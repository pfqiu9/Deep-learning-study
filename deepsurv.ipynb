{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ndata = pd.read_csv(\"/kaggle/input/breast-test/res_data1.csv\")\ntrain, test = train_test_split(data, test_size=0.2)\n\n\ntrain[\"flag\"] = 1\ntest[\"flag\"] = 0\n\n\ndata = pd.concat([train, test])\n\n\nfeatures_cat = [\"hualiao\",\"xiluoda\",\"fangliao\",\"neifenmi\",\"baxiang\",\"fufa\",\"yuanchuzhuanyi\",\"zuzhixue_leixing\",\n                \"T_fenqi\",\"fenhua_xuhao\",\"linbajie_zhuangtai\",\"N_fenqi\",\"TNM_fenqi\",\"012/3\",\"HR\",\"HER-2\",\n                \"Ki67\",\"CK56\",\"EGFR\",\"fenxing_xuhao\",\"shoushu_leibie\",\"OP4\"]\nfeatures_con = [\"mm\",\"LN\",\"CCI_score\",\"age_score\",\"age-CCI_score\"]\n\ndf_dummy = pd.get_dummies(data[features_cat])\ndata = pd.concat([data, df_dummy], axis = 1)\n\ntrain = data[data[\"flag\"] == 1]\ntest = data[data[\"flag\"] == 0]\n\n\nfeatures = df_dummy.columns.to_list() + features_con\ntrain_sel = train[[\"OS_month\", \"siwang\"] + features]\ntest_sel = test[[\"OS_month\", \"siwang\"] + features]\ntrain_sel.to_csv(\"/kaggle/working/data_train.csv\", index = False)\ntest_sel.to_csv(\"/kaggle/working/data_test.csv\", index = False)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-01T10:48:40.646705Z","iopub.execute_input":"2022-09-01T10:48:40.647923Z","iopub.status.idle":"2022-09-01T10:48:42.093724Z","shell.execute_reply.started":"2022-09-01T10:48:40.647766Z","shell.execute_reply":"2022-09-01T10:48:42.092104Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install pysurvival","metadata":{"execution":{"iopub.status.busy":"2022-09-01T10:57:13.203195Z","iopub.execute_input":"2022-09-01T10:57:13.203691Z","iopub.status.idle":"2022-09-01T10:58:58.186420Z","shell.execute_reply.started":"2022-09-01T10:57:13.203656Z","shell.execute_reply":"2022-09-01T10:58:58.185109Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pysurvival\n  Downloading pysurvival-0.1.2.tar.gz (4.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from pysurvival) (3.5.3)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pysurvival) (1.21.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from pysurvival) (1.3.5)\nRequirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from pysurvival) (22.1.2)\nCollecting progressbar\n  Downloading progressbar-2.5.tar.gz (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pyarrow in /opt/conda/lib/python3.7/site-packages (from pysurvival) (8.0.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from pysurvival) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from pysurvival) (1.7.3)\nRequirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (from pysurvival) (0.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pysurvival) (1.11.0+cpu)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pysurvival) (3.0.9)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pysurvival) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pysurvival) (1.4.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pysurvival) (21.3)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pysurvival) (4.33.3)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pysurvival) (2.8.2)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pysurvival) (9.1.1)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pysurvival) (2022.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pysurvival) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pysurvival) (3.1.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->pysurvival) (4.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->pysurvival) (1.15.0)\nBuilding wheels for collected packages: pysurvival, progressbar\n  Building wheel for pysurvival (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pysurvival: filename=pysurvival-0.1.2-cp37-cp37m-linux_x86_64.whl size=5331553 sha256=5e4bb44a37a46f03eed95f7f234da40d233b6fde5d3288ef1d558820a0b99995\n  Stored in directory: /root/.cache/pip/wheels/1a/63/e2/32273d765a4e2f4ccac69c8adf97425ca80bab5d0c8447f120\n  Building wheel for progressbar (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for progressbar: filename=progressbar-2.5-py3-none-any.whl size=12082 sha256=d8ee1cf280c5fb64acc6c5d3dc63a2022b3e92056608c5e33a860d82f971c602\n  Stored in directory: /root/.cache/pip/wheels/f0/fd/1f/3e35ed57e94cd8ced38dd46771f1f0f94f65fec548659ed855\nSuccessfully built pysurvival progressbar\nInstalling collected packages: progressbar, pysurvival\nSuccessfully installed progressbar-2.5 pysurvival-0.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom pysurvival.models.simulations import SimulationModel\nfrom pysurvival.models.semi_parametric import NonLinearCoxPHModel\nfrom pysurvival.utils.metrics import concordance_index\nfrom pysurvival.utils.metrics import brier_score\n# from pysurvival.utils.display import integrated_brier_score\nfrom pysurvival.utils.display import display_loss_values\n\n\n\ntrain = pd.read_csv(\"/kaggle/working/data_train.csv\")\ntest = pd.read_csv(\"/kaggle/working/data_test.csv\")\ntrain[\"flag\"] = 1\ntest[\"flag\"] = 0\n\n\ndata = pd.concat([train, test])\ndata[\"OS_month\"] = (data[\"OS_month\"] == 4).astype(int)\n\n\nfeatures_cat = [\"hualiao\", \"xiluoda\", \"fangliao\", \"zuzhixue_leixing\", \"TNM_fenqi\", \"baxiang\", \"CCI_score\", \"OP4\", \"neifenmi\"]\nfeatures_con = [\"age_score\", \"linbajie_zhuangtai\"]\n\n\ndf_dummy = pd.get_dummies(data[features_cat])\ndata = pd.concat([data, df_dummy], axis = 1)\n\n\n\ntrain = data[data[\"flag\"] == 1]\ntest = data[data[\"flag\"] == 0]\n\n\nfeatures = df_dummy.columns.to_list() + features_con\n\n# Creating the X, T and E input\nX_train, X_test = train[features].values, test[features].values\nT_train, T_test = train['siwang'].values, test['siwang'].values\nE_train, E_test = train['OS_month'].values, test['OS_month'].values\n\n\nlist_structure = [[{'activation': 'Sigmoid', 'num_units': 24}, \n                   {'activation': 'Sigmoid', 'num_units': 16}, \n                   {'activation': 'Sigmoid', 'num_units': 8},],\n                 [{'activation': 'Sigmoid', 'num_units': 10}, \n                   {'activation': 'Sigmoid', 'num_units': 8}, \n                   {'activation': 'Sigmoid', 'num_units': 6},],\n                 [{'activation': 'Sigmoid', 'num_units': 8}, \n                   {'activation': 'Sigmoid', 'num_units': 4}, \n                   {'activation': 'Sigmoid', 'num_units': 2},],\n                 [{'activation': 'Sigmoid', 'num_units': 36}, \n                   {'activation': 'Sigmoid', 'num_units': 6},],\n                 [{'activation': 'Sigmoid', 'num_units': 12}, \n                   {'activation': 'Sigmoid', 'num_units': 6},],\n                 [{'activation': 'Sigmoid', 'num_units': 8}, \n                   {'activation': 'Sigmoid', 'num_units': 4},],\n                 [{'activation': 'Sigmoid', 'num_units': 12}, \n                   {'activation': 'Sigmoid', 'num_units': 4},],]\n\n\n#### 4 - Creating an instance of the NonLinear CoxPH model and fitting the data.\nlist_lr = [0.1, 0.01, 0.001, 0.0001]\nlist_num_epochs = [500, 1000, 1500]\nlist_optimizer = [\"adadelta\", \"adagrad\", \"adam\", \"adamax\", \"rmsprop\", \"sgd\"]\n\n\n\nparameters = []\nfor structure in list_structure:\n    for lr in list_lr:\n        for num_epochs in list_num_epochs:\n            for optimizer in list_optimizer:\n                parameters.append([structure, lr, num_epochs, optimizer])\n\n\ndeepsurv_cv_results = pd.DataFrame(parameters)\nlist_cindex = []\nkf = KFold(n_splits = 5)\n\n\n\nfor parameter in parameters:\n    structure = parameter[0]\n    lr = parameter[1]\n    num_epochs = parameter[2]\n    optimizer = parameter[3]\n    \n    cindexes = []\n    for train_index, test_index in kf.split(train):\n        X_tr, X_val = X_train[train_index], X_train[test_index]\n        T_tr, T_val = T_train[train_index], T_train[test_index]\n        E_tr, E_val = E_train[train_index], E_train[test_index]\n        \n        # Building the model\n        nonlinear_coxph = NonLinearCoxPHModel(structure = structure)\n        nonlinear_coxph.fit(X_tr, T_tr, E_tr, l2_reg = 0, batch_normalization = False,\n                            verbose = True, \n                            lr = lr, num_epochs = num_epochs, optimizer = optimizer,\n                            dropout = 0.)\n        \n        #### 5 - Cross Validation / Model Performances\n        c_index = concordance_index(nonlinear_coxph, X_val, T_val, E_val)\n\n        cindexes.append(c_index)\n    list_cindex.append(np.mean(cindexes))\n    print(parameter, np.mean(cindexes))\n\n\ndeepsurv_cv_results[\"cindex\"] = list_cindex\ndeepsurv_cv_results.to_csv(\"/kaggle/working/deepsurv_cv_results.csv\", index = False)\n\n\n\ndef integrated_brier_score(model, X, T, E, t_max=None, use_mean_point=True):\n    \"\"\" The Integrated Brier Score (IBS) provides an overall calculation of \n        the model performance at all available times.\n    \"\"\"\n\n    # Computing the brier scores\n    times, brier_scores = brier_score(model, X, T, E, t_max, use_mean_point)\n\n    # Getting the proper value of t_max\n    if t_max is None:\n        t_max = max(times)\n    else:\n        t_max = min(t_max, max(times))\n\n    # Computing the IBS\n    ibs_value = np.trapz(brier_scores, times)/t_max \n\n    return ibs_value\n\n\ndeepsurv_cv_results = pd.read_csv(\"/kaggle/working/deepsurv_cv_results.csv\")\nprint(deepsurv_cv_results[\"cindex\"].values.max())\nind_best = deepsurv_cv_results[\"cindex\"].values.argmax()\nstructure = deepsurv_cv_results.iloc[ind_best, 0]\nlr = deepsurv_cv_results.iloc[ind_best, 1]\nnum_epochs = deepsurv_cv_results.iloc[ind_best, 2]\noptimizer = deepsurv_cv_results.iloc[ind_best, 3]\n\n\n# Building the model\nnonlinear_coxph = NonLinearCoxPHModel(structure = eval(structure))\nnonlinear_coxph.fit(X_train, T_train, E_train, l2_reg = 0, batch_normalization = False,\n                    verbose = True, \n                    lr = lr, num_epochs = num_epochs, optimizer = optimizer,\n                    dropout = 0.)\n\n#### 5 - Cross Validation / Model Performances\nc_index = concordance_index(nonlinear_coxph, X_test, T_test, E_test)\nprint('C-index: {:.4f}'.format(c_index))\n\nibs = integrated_brier_score(nonlinear_coxph, X_test, T_test, E_test)\nprint('IBS: {:.4f}'.format(ibs))\n\n\ndef bootstrap_replicate_1d(data):\n    bs_sample = np.random.choice(data,len(data))\n    return bs_sample\n\n\nbootstrap_R = 100\nc_indexes = []\nibss = []\n\n\nfor i in range(bootstrap_R):\n    print(i)\n    train_bs_idx = bootstrap_replicate_1d(np.array(range(train.shape[0])))\n    train_bs = train.iloc[train_bs_idx, ]\n    # Creating the X, T and E input\n    X_train = train_bs[features].values\n    T_train = train_bs['siwang'].values\n    E_train = train_bs['OS_month'].values\n    \n    # Building the model\n    nonlinear_coxph = NonLinearCoxPHModel(structure = eval(structure))\n    nonlinear_coxph.fit(X_train, T_train, E_train, l2_reg = 0, batch_normalization = False,\n                        verbose = True, \n                        lr = lr, num_epochs = num_epochs, optimizer = optimizer,\n                        dropout = 0.)\n\n    #### 5 - Cross Validation / Model Performances\n    c_index = concordance_index(nonlinear_coxph, X_test, T_test, E_test)\n    c_indexes.append(np.round(c_index, 4))\n\n    ibs = integrated_brier_score(nonlinear_coxph, X_test, T_test, E_test)\n    ibss.append(np.round(ibs, 4))\n\n\npd.DataFrame(data = {\"cindex\": c_indexes, \"ibs\": ibss}).to_csv(\"/kaggle/working/results.ci.deepsurv.csv\", index=False)\n\n# Compute the 95% confidence interval: conf_int\nmean_cindex = np.mean(c_indexes)\nmean_ibs = np.mean(ibss)\n\n# Print the mean\nprint('mean cindex =', mean_cindex)\nprint('mean ibs =', mean_ibs)\n\n\nci_cindex = np.percentile(c_indexes, [2.5, 97.5])\nci_ibs = np.percentile(ibss, [2.5, 97.5])\n \n# Print the confidence interval\nprint('confidence interval =', ci_cindex)\nprint('confidence interval =', ci_ibs)","metadata":{"execution":{"iopub.status.busy":"2022-09-01T11:00:41.431770Z","iopub.execute_input":"2022-09-01T11:00:41.432346Z","iopub.status.idle":"2022-09-01T11:00:41.535078Z","shell.execute_reply.started":"2022-09-01T11:00:41.432299Z","shell.execute_reply":"2022-09-01T11:00:41.533495Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/423927806.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m                             \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                             \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                             dropout = 0.)\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m#### 5 - Cross Validation / Model Performances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pysurvival/models/semi_parametric.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, T, E, init_method, optimizer, lr, num_epochs, dropout, batch_normalization, bn_and_dropout, l2_reg, verbose)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_time_buckets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;31m# Initializing the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pysurvival/models/__init__.py\u001b[0m in \u001b[0;36mget_time_buckets\u001b[0;34m(self, extra_timepoint)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'The time axis needs to be created before'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m' using the method get_time_buckets.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# Creating the base time buckets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: The time axis needs to be created before using the method get_time_buckets."],"ename":"AttributeError","evalue":"The time axis needs to be created before using the method get_time_buckets.","output_type":"error"}]}]}